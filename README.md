# dsc232r-amazon-predictive-modeling

Download the dataset and save unzipped files in a folder named 'amazon_data':
https://www.kaggle.com/datasets/cynthiarempel/amazon-us-customer-reviews-dataset

In processing our dataset, proper data preparation is crucial to ensure the quality and effectiveness of our analysis. Here are the specific steps we have taken:

### Missing Value Handling
For the essential fields `review_body` and `review_date`, which are critical for our analysis due to their relevance to the review content and timing, we will remove any rows with missing values in these columns. The absence of this information renders the row useless for trend analysis. For missing values in the `product_category` field, since adjacent entries usually belong to the same category, we will employ a forward-fill method to maintain data continuity. Missing values in other fields will be filled based on their data type using the median or mode.

### Data Filtering and Simplification
Given the low proportion of Vine program reviews (only 2,982 out of 523,269), which is too minor to significantly impact our analysis, we have decided to drop this column. Similarly, since all data comes from the US market (the `marketplace` column is always 'US'), this column is redundant and will be removed to save storage space and computational resources.

### Data Time Range Adjustment
Observing that the volume of data increases over the years, likely reflecting the growing base of Amazon users, we will discard data from before 2010. This approach focuses the model training on more representative and relevant data, enhancing the accuracy of predicting future trends.

### Data Encoding and Text Processing
Text category labels, such as `product_category`, will be converted into numerical codes to reduce the complexity of model processing and improve computational efficiency. We will also tokenize the review texts, which are essential for extracting useful information and patterns for text analysis. And we also changed title into vectors and changed text into vectors.

### Anomaly Data Handling
We will identify and remove reviews likely generated by automated scripts, as such data typically feature monotonous sentiments and high repetition rates, which could affect the model's accuracy and generalizability.

### Feature Standardization
We will standardize or normalize numerical features, especially when using distance-based models, to optimize model performance and predictive capabilities.

### Dataset Splitting
Data will be split into training and testing sets according to the time order, with the most recent data used as the test set. This setup simulates real-world predictions of product trends, ensuring that the model performs well on unseen data.

Through these meticulous data preprocessing steps, our dataset will be cleaner, more effective, and ready to build an accurate predictive model.

### Count Product Reviews Per Day
Group by unique product identifier and day to get reviews per day for each product

### Data Modeling 
In the initial data modeling phase, the training set consists of data from the year 2014, while the test set comprises data from the year 2015. Upon plotting all the product review counts as a reference to verified product purchases, it is observed that product_category_num 32 registers the highest number of purchases throughout the year. Although the upcoming model will be designed to handle multiple categories over multiple years, the initial focus of the data modeling phase is on a single category over a single year to assess the accuracy and adaptability of the model.

To forecast the 2015 purchases of products in category 32, the ARIMA (AutoRegressive Integrated Moving Average) model is utilized. It analyzes the span of 12 months in the year 2014 to predict the purchases in 2015. The ARIMA model endeavors to predict future values—in this case, purchases—by discerning patterns and relationships from previous data.

The subsequent model will expand upon the current one, possibly incorporating the usage of word2vector data to identify popular buzzwords indicating an influx in popularity.

### Answer the questions
* Where does your model fit in the fitting graph? and What are the next models you are thinking of and why?

Based on the ARIMA model for product_category_num 32 of the year 2014, we forcasted the estimate of sales (with assumption based on reviews). The next models will include more training data, prior to 2014 for all product catgeories. We may possibily utilize the word2vector data to see the primary key words that have the highest count of reviews which we assume correlates to high counts of purchases. Through this we can forcast what speciifc item or product_category_num will increase in sales. However before moving on to more complicated models, our team will focus on building upon the ARIMA model to more acurately forcast which product_category_num is rise in sales/popular as the forcasted and test data concluded with a RMSE of 28498.15662477966.

### Conclusion section
* What is the conclusion of your 1st model? What can be done to possibly improve it?
  
The 1st model concluded with an RMSE of 28498.156. This isn't the best given that there is almost a difference of 30k of the forcsted and the actualy 2015 test data for the product_category_num 32. We can increase the training data from 2014 to the range of 2010 to 2014. We do this for all the product_category_num to be able to accurately predict which item is more popular.  By increasing the training data we will be able to catch more underlying patterns thorughout the years. 
