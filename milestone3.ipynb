{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Amazon Review Data : Data Exploration\n",
    "\n",
    "### Setup spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os, pickle, glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.sql import SparkSession, SQLContext, DataFrame\n",
    "from pyspark.sql.types import StringType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.ml.feature import Word2Vec, Tokenizer, StringIndexer, OneHotEncoder, PCA, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkSession.builder \\\n",
    "    .config(\"spark.driver.memory\", \"64g\") \\\n",
    "\t.config(\"spark.executor.memory\", \"32g\") \\\n",
    "    .config('spark.executor.instances', 5) \\\n",
    "\t.appName(\"Amazon Reviews\") \\\n",
    "\t.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Read Data\n",
    "\n",
    "### Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "###################### change path to: \"../clin6/amazon_data\" #########################\n",
    "#######################################################################################\n",
    "path = \"../clin6/amazon_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(path):\n",
    "    \"\"\"\n",
    "    Method that loads data file as df\n",
    "    Takes in 1 parameter: path\n",
    "    \"\"\"\n",
    "    return sc.read.csv(path, sep = \"\\t\", header = True, inferSchema = True)\n",
    "\n",
    "def get_path(file):\n",
    "    \"\"\"\n",
    "    Method to create path\n",
    "    Takes in 1 parameter: file name\n",
    "    \"\"\"\n",
    "    return \"amazon_data/%s\" % file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.listdir(path)\n",
    "files = [f for f in dir if os.path.isfile(os.path.join(path, f))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_df(files):\n",
    "    \"\"\"\n",
    "    Method that combines files into 1 big df\n",
    "    Takes in 1 parameter: list of file names\n",
    "    \"\"\"\n",
    "    df = None\n",
    "    n = len(files)\n",
    "    for i in range(n):\n",
    "        data = read(get_path(files[i]))\n",
    "        if df is None:\n",
    "            df = data\n",
    "        else:\n",
    "            df = df.union(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "* Finish major preprocessing, this includes scaling and/or transforming your data, imputing your data, encoding your data, feature expansion, Feature expansion (example is taking features and generating new features by transforming via polynomial, log multiplication of features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_category_column = 'product_category'\n",
    "review_body_column = 'review_body'\n",
    "review_date_column = 'review_date'\n",
    "title_column = 'product_title'\n",
    "category_column = 'product_category'\n",
    "product_parent_column = 'product_parent'\n",
    "review_body_column = 'review_body'\n",
    "verified_purchase_column = 'verified_purchase'\n",
    "\n",
    "product_category_col = F.col(product_category_column)\n",
    "review_body_col = F.col(review_body_column)\n",
    "review_date_col = F.col(review_date_column)\n",
    "title_col = F.col(title_column)\n",
    "category_col = F.col(category_column)\n",
    "product_parent_col = F.col(product_parent_column)\n",
    "review_body_col = F.col(review_body_column)\n",
    "verified_purchase_col = F.col(verified_purchase_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data & Take care of missing categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imputed_df(files, category = True):\n",
    "    \"\"\"\n",
    "    Method that combines files into 1 big df\n",
    "    Takes in 1 parameter: list of file names\n",
    "    \"\"\"\n",
    "    df = None\n",
    "    n = len(files)\n",
    "    categories = {}\n",
    "    for i in range(n):\n",
    "        data = read(get_path(files[i]))\n",
    "        \n",
    "        # Fill in null categories\n",
    "        if category:\n",
    "            cat = files[i][18:-10]\n",
    "            categories[cat] = i\n",
    "            data = data.withColumn(product_category_column,\n",
    "                                   product_category_col).fillna(cat)\n",
    "        \n",
    "        if df is None:\n",
    "            df = data\n",
    "        else:\n",
    "            df = df.union(data)\n",
    "    return df, categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get df & Remove Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, categories = get_imputed_df(files)\n",
    "df = df.drop('marketplace', 'vine').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.registerDataFrameAsTable(df, \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "num_cols = len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out rows with missing body and date and verified purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(review_body_col.isNotNull() & review_date_col.isNotNull() & verified_purchase_col = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(F.year(review_date_col) >= 2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check other missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'customer_id' column has 0 missing values\n",
      "'review_id' column has 0 missing values\n",
      "'product_id' column has 0 missing values\n",
      "'product_parent' column has 0 missing values\n",
      "'product_title' column has 0 missing values\n",
      "'product_category' column has 0 missing values\n",
      "'star_rating' column has 0 missing values\n",
      "'helpful_votes' column has 0 missing values\n",
      "'total_votes' column has 0 missing values\n",
      "'verified_purchase' column has 0 missing values\n",
      "'review_headline' column has 0 missing values\n",
      "'review_body' column has 0 missing values\n",
      "'review_date' column has 0 missing values\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_cols):\n",
    "    missing = df.filter(df[columns[i]].isNull()).count()\n",
    "    print(\"'%s' column has %d missing values\" % (columns[i], missing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* No more missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_column = 'month'\n",
    "year_column = 'year'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(month_column, F.year(review_date_col)).withColumn(year_column, F.column(review_date_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match category to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_num_col = 'product_category_num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(dic): \n",
    "    return F.udf(lambda x: dic.get(x), StringType()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(category_num_col, translate(categories)(category_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change title into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleArray_column = 'titleArray'\n",
    "titleVector_column = 'titleVector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(titleArray_column, F.split(F.lower(F.col(title_column)), ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(inputCol = titleArray_column, outputCol = titleVector_column,\n",
    "                    minCount = 100, vectorSize = 16, numPartitions = 4)\n",
    "model = word2vec.fit(df)\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change text into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewArray_column = 'reviewArray'\n",
    "reviewVector_column = 'reviewVector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(reviewArray_column, F.split(F.lower(F.col(review_body_column)), ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(inputCol = reviewArray_column, outputCol = reviewVector_column,\n",
    "                    minCount = 100, vectorSize = 16, numPartitions = 4)\n",
    "model = word2vec.fit(df)\n",
    "df = model.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Splitting\n",
    "* Use last year as test and the rest as train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.filter(F.year(review_date_col) < 2015)\n",
    "test = df.filter(F.year(review_date_col) >= 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74210623\n",
      "29736522\n"
     ]
    }
   ],
   "source": [
    "print(train.count())\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Product Reviews Per Day\n",
    "* Group by unique product identifier and day to get reviews per day for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(review_date_col, product_parent_col).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data modeling\n",
    "* Train your first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Evaluation\n",
    "* Evaluate your model and compare training vs. test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer the questions\n",
    "* Where does your model fit in the fitting graph? and What are the next models you are thinking of and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion section\n",
    "* What is the conclusion of your 1st model? What can be done to possibly improve it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "190px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "514px",
    "left": "0px",
    "right": "925px",
    "top": "107px",
    "width": "323px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
